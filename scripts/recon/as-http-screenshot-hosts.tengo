fmt := import("fmt")
text := import("text")
os := import("os")
filepath := import("filepath")
slice := import("slice")
arsenic := import("arsenic")
url := import("url")
script := import("script")
times := import("times")
log := import("log")
rand := import("rand")
git := import("git")

wordlistFile := ""
wordlistName := ""
manual := true

action := "scan"
if args.action {
  action = args.action
}

argHost := ""
if args.host {
  argHost = args.host
}

proxy := ""
if args.proxy {
  proxy = args.proxy
}

getURLs := func() {
  re := text.re_compile(`\.(png|jpe?g|ico|css|gif|js)$`)

  urls := []
  codes := [200]
  patterns := ["recon/gobuster.*.txt", "recon/ffuf.*.json", "recon/dirb.*.txt"]
  
  discoveredURLs := arsenic.content_discovery_urls(patterns, codes)
  if is_error(discoveredURLs) {
    script.stop(discoveredURLs)
  }

  for u in discoveredURLs {
    if re.match(u) {
      continue
    }

    urls = append(urls, u)
  }

  urls = slice.unique(urls)
  if is_error(urls) {
    script.stop(urls)
  }

  return urls
}

getHosts := func() {
  git.pull()

  paths := arsenic.host_paths(["web-content"])
  if is_error(paths) {
    script.stop(paths)
  }

  for path in paths {
    if filepath.exists(filepath.join(path, "recon", "wordlist-content-discover.txt")) {
      
    }
  }
}

// scanHost := func(host, rawURL) {
//   log.msg(format("Content Discovery / %s / %s / checking", host, rawURL))
//   // check if host is a draft

//   // do the following only if the host isn't a draft
//   log.info(format("Content Discovery / %s / %s / preparing", host, rawURL))

//   previousDir := os.getwd()
//   if is_error(previousDir) {
//     script.stop(previousDir)
//   }

//   err := os.chdir(filepath.join("hosts", host))
//   if is_error(err) {
//     script.stop(err)
//   }
  
//   outputFile := genOutputFileName(rawURL)

//   git.pull()

//   outputPath := filepath.join("recon", outputFile)
//   if !filepath.exists(outputPath) {
//     log.msg(format("Scanning %s %s", host, rawURL))

//     // check if url is S3 bucket

//     err = git.lock(outputPath, format("ffuf lock: %s", rawURL))
//     if is_error(err) {
//       script.stop(err)
//     }

//     log.info(format("Content Discovery / %s / %s / running", host, rawURL))

//     err = arsenic.ffuf("-a", "Firefox", "-u", rawURL, "-w", wordlistFile, "-o", outputFile)
//     if is_error(err) {
//       script.stop(err)
//     }

//     log.info(format("Content Discovery / %s / %s / complete", host, rawURL))
//   }

//   err = git.commit(".", format("ffuf complete: %s", rawURL))
//   if is_error(err) {
//     script.stop(err)
//   }

//   err = os.chdir(previousDir)
//   if is_error(err){
//     script.stop(err)
//   }
// }

// err := git.pull()
// if is_error(err) {
//   script.stop(err)
// }

if action == "list" {
  urls := getURLs()
  for u in urls {
    fmt.println(u)
  }
  script.stop()
}

// autoSelect := func() {
//   elem := slice.rand_item(getHostURLs())
//   if !elem {
//     files := arsenic.locked_files("hosts/*/recon/ffuf*.json")
//     if is_error(files) {
//       script.stop(files)
//     }

//     if len(files) > 0 {
//       log.warn("other ffufs are still running... lets wait before continuing")
//       script.stop()
//     }

//     script.stop("No host found")
//   }
  
//   argHost = text.fields(elem)[0]
//   argURL = text.fields(elem)[1]

//   log.warn(format("Auto selected %s %s", argHost, argURL))
// }

// if argHost == "" {
//   manual = false
//   log.warn("no args found, autodetecting")

//   autoSelect()
// }

// for {
//   scanHost(argHost, argURL)
//   if manual {
//     break
//   }

//   autoSelect()
// }

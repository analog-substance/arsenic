fmt := import("fmt")
text := import("text")
os := import("os")
filepath := import("filepath")
slice := import("slice")
arsenic := import("arsenic")
url := import("url")
script := import("script")
times := import("times")
log := import("log")
rand := import("rand")
git := import("git")

wordlistFile := ""
wordlistName := ""
manual := true

action := "scan"
if args.action {
  action = args.action
}

argHost := ""
if args.host {
  argHost = args.host
}

proxy := ""
if args.proxy {
  proxy = args.proxy
}

getURLs := func() {
  re := text.re_compile(`\.(png|jpe?g|ico|css|gif|js)$`)

  codes := [200]
  urls := []
  for u in arsenic.content_discovery_urls("recon/gobuster.*.txt", codes) {
    if re.match(u) {
      continue
    }

    urls = append(urls, u)
  }

  for u in arsenic.content_discovery_urls("recon/ffuf.*.json", codes) {
    if re.match(u) {
      continue
    }

    urls = append(urls, u)
  }

  for u in arsenic.content_discovery_urls("recon/dirb.*.txt", codes) {
    if re.match(u) {
      continue
    }

    urls = append(urls, u)
  }

  return 
}

getHostURLs := func() {
  urls := arsenic.host_urls("http")
  if is_error(urls) {
    script.stop(urls)
  }

  hostURLs := []
  for rawURL in urls {
    hostname := url.hostname(rawURL)
    if is_error(hostname) {
      script.stop(hostname)
    }

    hostPath := arsenic.host_path(hostname)
    if is_error(hostPath) {
      script.stop(hostPath)
    }

    host := filepath.base(hostPath)

    outputFile := genOutputFileName(rawURL)
    
    if !filepath.exists(filepath.join(hostPath, "recon", outputFile)) {
      hostURLs = append(hostURLs, fmt.sprintf("%s %s", host, rawURL))
    }
  }

  return hostURLs
}

scanHost := func(host, rawURL) {
  log.msg(format("Content Discovery / %s / %s / checking", host, rawURL))
  // check if host is a draft

  // do the following only if the host isn't a draft
  log.info(format("Content Discovery / %s / %s / preparing", host, rawURL))

  previousDir := os.getwd()
  if is_error(previousDir) {
    script.stop(previousDir)
  }

  err := os.chdir(filepath.join("hosts", host))
  if is_error(err) {
    script.stop(err)
  }
  
  outputFile := genOutputFileName(rawURL)

  git.pull()

  outputPath := filepath.join("recon", outputFile)
  if !filepath.exists(outputPath) {
    log.msg(format("Scanning %s %s", host, rawURL))

    // check if url is S3 bucket

    err = git.lock(outputPath, format("ffuf lock: %s", rawURL))
    if is_error(err) {
      script.stop(err)
    }

    log.info(format("Content Discovery / %s / %s / running", host, rawURL))

    err = arsenic.ffuf("-a", "Firefox", "-u", rawURL, "-w", wordlistFile, "-o", outputFile)
    if is_error(err) {
      script.stop(err)
    }

    log.info(format("Content Discovery / %s / %s / complete", host, rawURL))
  }

  err = git.commit(".", format("ffuf complete: %s", rawURL))
  if is_error(err) {
    script.stop(err)
  }

  err = os.chdir(previousDir)
  if is_error(err){
    script.stop(err)
  }
}

err := git.pull()
if is_error(err) {
  script.stop(err)
}

if action == "list" {
  hostURLs := getHostURLs()
  for hostURL in hostURLs {
    fmt.println(hostURL)
  }
  script.stop()
}

autoSelect := func() {
  elem := slice.rand_item(getHostURLs())
  if !elem {
    files := arsenic.locked_files("hosts/*/recon/ffuf*.json")
    if is_error(files) {
      script.stop(files)
    }

    if len(files) > 0 {
      log.warn("other ffufs are still running... lets wait before continuing")
      script.stop()
    }

    script.stop("No host found")
  }
  
  argHost = text.fields(elem)[0]
  argURL = text.fields(elem)[1]

  log.warn(format("Auto selected %s %s", argHost, argURL))
}

if argHost == "" {
  manual = false
  log.warn("no args found, autodetecting")

  autoSelect()
}

for {
  scanHost(argHost, argURL)
  if manual {
    break
  }

  autoSelect()
}

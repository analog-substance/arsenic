#!/usr/bin/env arsenic

fmt := import("fmt")
text := import("text")
os := import("os")
filepath := import("filepath")
slice := import("slice")
arsenic := import("arsenic")
script := import("script")
log := import("log")
git := import("git")
set := import("set")
cobra := import("cobra")

genOutputFileName := func(rawURL, wordlistName) {
  rawURL = text.replace(rawURL, "://", ".", -1)
  rawURL = text.replace(rawURL, "/", ".", -1)
  return fmt.sprintf("ffuf.%s.%s.json", rawURL, wordlistName)
}

getHostURLs := func(flags, wordlistName) {
  hosts := arsenic.hosts(flags)
  if is_error(hosts) {
    script.stop(hosts)
  }

  hostURLs := []
  urlSet := set.new_string_set()
  for host in hosts {
    urls := host.urls("http")
    if is_error(urls) {
      script.stop(urls)
    }

    for rawURL in urls {
      success := urlSet.add(rawURL)
      if is_error(success) {
        script.stop(success)
      }

      if !success {
        continue
      }

      outputFile := genOutputFileName(rawURL, wordlistName)
      
      exists := host.file_exists(filepath.join("recon", outputFile))
      if is_error(exists) {
        script.stop(exists)
      }

      if !exists {
        hostURLs = append(hostURLs, format("%s %s", host.name, rawURL))
      }
    }
  }

  return hostURLs
}

flags := []
wordlistFile := ""
wordlistName := ""

rootCmd := cobra.root_cmd("as-content-discovery.tengo", "Run content enumeration on current scope")
rootCmd.persistent_flags.string_slicep("flags", "f", [], "Filter hosts by flags")

rootCmd.set_persistent_pre_run(func(cmd, args) {
  flags = cmd.flags.get_string_slice("flags")

  wordlistFile = filepath.abs("recon/wordlist-content-discover.txt")
  if is_error(wordlistFile) {
    script.stop(wordlistFile)
  }

  if !filepath.file_exists(wordlistFile) {
    log.info("Generating wordlist...")
    err := arsenic.gen_wordlist("web-content", wordlistFile)
    if is_error(err) {
      script.stop(err)
    }
  }

  wordlistName = filepath.base(wordlistFile)
  wordlistName = text.trim_suffix(wordlistName, filepath.ext(wordlistName))

  err := git.pull()
  if is_error(err) {
    script.stop(err)
  }
})

listCmd := cobra.cmd("list", "Lists the hosts that need content enumeration")
rootCmd.add_command(listCmd)

listCmd.set_run(func(cmd, args) {
	hostURLs := getHostURLs(flags, wordlistName)
  for hostURL in hostURLs {
    fmt.println(hostURL)
  }
})

scanCmd := cobra.cmd("scan", "Scan hosts that need content enumeration")
scanCmd.flags.stringp("host", "H", "", "Host to scan. Must be used with --url.")
scanCmd.flags.stringp("url", "u", "", "URL to scan. Must be used with --host.")
rootCmd.add_command(scanCmd)

scanCmd.set_run(func(cmd, args) {
  targetHost := cmd.flags.get_string("host")
  targetURL := cmd.flags.get_string("url")

  manual := targetHost != "" && targetURL != ""

  if (targetHost != "" && targetURL == "") || (targetHost == "" && targetURL != "") {
    script.stop("[!] Host and URL must not be empty.")
  }

	autoSelect := func() {
    elem := slice.rand_item(getHostURLs(flags, wordlistName))
    if !elem {
      files := arsenic.locked_files("hosts/*/recon/ffuf*.json")
      if is_error(files) {
        script.stop(files)
      }

      if len(files) > 0 {
        log.warn("other ffufs are still running... lets wait before continuing")
        script.stop()
      }

      script.stop("No host found")
    }
    
    targetHost = text.fields(elem)[0]
    targetURL = text.fields(elem)[1]

    log.warn(format("Auto selected %s %s", targetHost, targetURL))
  }

  scanHost := func(host, rawURL) {
    log.msg(format("Content Discovery / %s / %s / checking", host, rawURL))
    // check if host is a draft

    // do the following only if the host isn't a draft
    log.info(format("Content Discovery / %s / %s / preparing", host, rawURL))

    previousDir := os.getwd()
    if is_error(previousDir) {
      script.stop(previousDir)
    }

    err := os.chdir(filepath.join("hosts", host))
    if is_error(err) {
      script.stop(err)
    }
    
    outputFile := genOutputFileName(rawURL, wordlistName)

    git.pull()

    outputPath := filepath.join("recon", outputFile)
    if !filepath.file_exists(outputPath) {
      log.msg(format("Scanning %s %s", host, rawURL))

      // check if url is S3 bucket

      err = git.lock(outputPath, format("ffuf lock: %s", rawURL))
      if is_error(err) {
        script.stop(err)
      }

      log.info(format("Content Discovery / %s / %s / running", host, rawURL))

      err = arsenic.ffuf("-a", "Firefox", "-u", rawURL, "-w", wordlistFile, "-o", outputFile)
      if is_error(err) {
        script.stop(err)
      }

      log.info(format("Content Discovery / %s / %s / complete", host, rawURL))
    }

    err = git.commit(".", format("ffuf complete: %s", rawURL))
    if is_error(err) {
      script.stop(err)
    }

    err = os.chdir(previousDir)
    if is_error(err){
      script.stop(err)
    }
  }

  if !manual {
    log.warn("no args found, autodetecting")

    autoSelect()
  }

  for {
    scanHost(targetHost, targetURL)
    if manual {
      break
    }

    autoSelect()
  }
})

err := rootCmd()
if is_error(err) {
	script.stop(err)
}

#!/usr/bin/env arsenic

fmt := import("fmt")
text := import("text")
os := import("os")
os2 := import("os2")
json := import("json")
filepath := import("filepath")
slice := import("slice")
arsenic := import("arsenic")
script := import("script")
log := import("log")
git := import("git")
set := import("set")
cobra := import("cobra")
check_err := import("check_err")

genOutputFileName := func(rawURL, wordlistName) {
  rawURL = text.replace(rawURL, "://", ".", -1)
  rawURL = text.replace(rawURL, "/", ".", -1)
  return fmt.sprintf("ffuf.%s.%s.json", rawURL, wordlistName)
}

getHostURLs := func(flags, wordlistName) {
  hosts := arsenic.hosts(flags)
  check_err(hosts)

  hostURLs := []
  urlSet := set.new_string_set()
  for host in hosts {
    urls := host.urls("http")
    check_err(urls)

    for rawURL in urls {
      success := urlSet.add(rawURL)
      check_err(success)

      if !success {
        continue
      }

      outputFile := genOutputFileName(rawURL, wordlistName)
      
      exists := host.file_exists(filepath.join("recon", outputFile))
      check_err(exists)

      if !exists {
        hostURLs = append(hostURLs, format("%s %s", host.name, rawURL))
      }
    }
  }

  return hostURLs
}

flags := []
wordlistFile := ""
wordlistName := ""

rootCmd := cobra.root_cmd(script.name, "Run content enumeration on current scope")
rootCmd.persistent_flags.string_slicep("flags", "f", [], "Filter hosts by flags")
rootCmd.add_disable_git_flag()

rootCmd.set_persistent_pre_run(func(cmd, args) {
  flags = cmd.flags.get_string_slice("flags")

  wordlistFile = filepath.abs("recon/wordlist-content-discover.txt")
  check_err(wordlistFile)

  if !filepath.file_exists(wordlistFile) {
    log.info("Generating wordlist...")
    err := arsenic.gen_wordlist("web-content", wordlistFile)
    check_err(err)
  }

  wordlistName = filepath.base(wordlistFile)
  wordlistName = text.trim_suffix(wordlistName, filepath.ext(wordlistName))

  err := git.pull()
  check_err(err)
})

listCmd := cobra.cmd("list", "Lists the hosts that need content enumeration")
rootCmd.add_command(listCmd)

listCmd.set_run(func(cmd, args) {
	hostURLs := getHostURLs(flags, wordlistName)
  for hostURL in hostURLs {
    fmt.println(hostURL)
  }
})

scanCmd := cobra.cmd("scan", "Scan hosts that need content enumeration")
scanCmd.flags.stringp("host", "H", "", "Host to scan. Must be used with --url.")
scanCmd.flags.stringp("url", "u", "", "URL to scan. Must be used with --host.")
rootCmd.add_command(scanCmd)

scanCmd.set_run(func(cmd, args) {
  targetHost := cmd.flags.get_string("host")
  targetURL := cmd.flags.get_string("url")

  manual := targetHost != "" && targetURL != ""

  if (targetHost != "" && targetURL == "") || (targetHost == "" && targetURL != "") {
    script.stop("[!] Host and URL must not be empty.")
  }

	autoSelect := func() {
    elem := slice.rand_item(getHostURLs(flags, wordlistName))
    if !elem {
      files := arsenic.locked_files("hosts/*/recon/ffuf*.json")
      check_err(files)

      if len(files) > 0 {
        log.warn("other ffufs are still running... lets wait before continuing")
        script.stop()
      }

      script.stop("No host found")
    }
    
    targetHost = text.fields(elem)[0]
    targetURL = text.fields(elem)[1]

    log.warn(format("Auto selected %s %s", targetHost, targetURL))
  }

  scanHost := func(host, rawURL) {
    log.msg(format("Content Discovery / %s / %s / checking", host, rawURL))
    // check if host is a draft

    // do the following only if the host isn't a draft
    log.info(format("Content Discovery / %s / %s / preparing", host, rawURL))

    previousDir := os.getwd()
    check_err(previousDir)

    err := os.chdir(filepath.join("hosts", host))
    check_err(err)
    
    outputFile := genOutputFileName(rawURL, wordlistName)

    git.pull()

    outputPath := filepath.join("recon", outputFile)
    if !filepath.file_exists(outputPath) {
      log.msg(format("Scanning %s %s", host, rawURL))

      // check if url is S3 bucket

      err = git.lock(outputPath, format("ffuf lock: %s", rawURL))
      check_err(err)

      log.info(format("Content Discovery / %s / %s / running", host, rawURL))

      err = arsenic.ffuf("-a", "Firefox", "-u", rawURL, "-w", wordlistFile, "-o", outputFile)
      check_err(err)

      // If there were warnings (i.e. ffuf exited due to errors), let's add them to the JSON file
      if type_name(err) == "array" && len(err) != 0 && type_name(err[0]) == "warning" {
        content := os.read_file(outputPath)
        check_err(content)

        obj := json.decode(content)

        warnings := []
        for warning in err {
          warnings = append(warnings, warning.value)
        }
        obj.warnings = warnings

        content = json.encode(obj)
        content = json.indent(content, "", "  ")

        err = os2.write_file(outputPath, content)
        check_err(err)
      }

      log.info(format("Content Discovery / %s / %s / complete", host, rawURL))
    }

    err = git.commit(".", format("ffuf complete: %s", rawURL))
    check_err(err)

    err = os.chdir(previousDir)
    check_err(err)
  }

  if !manual {
    log.warn("no args found, autodetecting")

    autoSelect()
  }

  for {
    scanHost(targetHost, targetURL)
    if manual {
      break
    }

    autoSelect()
  }
})

err := rootCmd()
check_err(err)
